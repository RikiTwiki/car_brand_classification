{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 16:27:52.658543: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-26 16:27:52.988997: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-26 16:27:52.990649: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-26 16:27:54.103242: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_yolov8 as yolov8\n",
    "# import tensorflow_object_detection_api as tfod\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Detection Model\n",
    "object_detection_model = YOLO('yolov8x.pt')\n",
    "\n",
    "# Car Make Recognition Model\n",
    "car_make_recognition_model = load_model('car_brands_model_v27.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 car, 569.4ms\n",
      "Speed: 8.9ms preprocess, 569.4ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_keys', 'boxes', 'cpu', 'cuda', 'keypoints', 'masks', 'names', 'new', 'numpy', 'orig_img', 'orig_shape', 'path', 'plot', 'probs', 'save_crop', 'save_dir', 'save_txt', 'speed', 'to', 'tojson', 'update', 'verbose']\n",
      "Failed to load object detection model or detect car in image.\n"
     ]
    }
   ],
   "source": [
    "def single_out_car_and_recognize_make(image):\n",
    "\n",
    "    if object_detection_model is None:\n",
    "        return None\n",
    "\n",
    "    detections = object_detection_model(image)\n",
    "\n",
    "    # Check if detections is empty or None\n",
    "    if not detections or len(detections) == 0:\n",
    "        return None\n",
    "\n",
    "    # Extract the Results object\n",
    "    results = detections[0]\n",
    "\n",
    "    # Debugging: print out the attributes of the results object\n",
    "    print(dir(results))\n",
    "\n",
    "    # Extract bounding boxes\n",
    "    bounding_boxes = results.boxes.xyxy  # Assuming the boxes are in xyxy format\n",
    "\n",
    "    # TODO: Once you identify the right attribute for labels, replace this line\n",
    "    # For now, I'm setting labels as an empty list for the code to continue\n",
    "    labels = []\n",
    "\n",
    "    # Extract bounding boxes for cars\n",
    "    car_bounding_boxes = [box for i, box in enumerate(bounding_boxes) if i < len(labels) and results.names[labels[i]] == 'car']\n",
    "\n",
    "    # Check if there are detected cars\n",
    "    if not car_bounding_boxes:\n",
    "        return None\n",
    "\n",
    "    # Crop the car from the image using the first detected car bounding box\n",
    "    car_bounding_box = car_bounding_boxes[0]\n",
    "    car_image = image[int(car_bounding_box[1]):int(car_bounding_box[3]), int(car_bounding_box[0]):int(car_bounding_box[2])]\n",
    "\n",
    "    # Resize the car image to the input size of the car make recognition model\n",
    "    car_image = tf.image.resize(car_image, (224, 224))\n",
    "\n",
    "    # Recognize the make of the car\n",
    "    car_make = car_make_recognition_model.predict(car_image)\n",
    "\n",
    "    return car_make\n",
    "\n",
    "# Example usage\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image = np.array(Image.open(\"kok.jpg\"))  # You can change the target size to whatever you require\n",
    "\n",
    "# Single out the car and recognize the make\n",
    "car_make = single_out_car_and_recognize_make(image)\n",
    "\n",
    "# Print the car make\n",
    "if car_make is not None:\n",
    "    print(car_make)\n",
    "else:\n",
    "    print(\"Failed to load object detection model or detect car in image.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
